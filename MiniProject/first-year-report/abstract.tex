
\addcontentsline{toc}{chapter}{Abstract}
\begin{center}
%{{\fontsize{16}{15} \bf ABSTRACT}\\}
{\fontsize{16}{15} \bf ABSTRACT}
\vspace{0.4cm}
\end{center}
\normalsize

Deep learning 
models---also known as deep neural network (DNN) models---are 
a critical component of AI systems 
used in high-stake domains 
such as 
autonomous driving and
medical diagnostics, \alexcomment{and 
security}{Don't get this; what aspect of security}.
Deploying these models in real-world, safety-critical 
scenarios requires rigorous, measurable robustness 
testing to account for 
diverse environmental conditions.
Current metrics like \emph{neuron coverage}
do not fully capture all corner cases, 
which can lead to unexpected model failures. 
My research introduces 
a comprehensive testing framework that enhances 
the correctness evaluation of models through a 
structured five-stage process:
(1) \emph{specification} defines 
essential system properties to guide the entire testing process 
and ensure comprehensive coverage;
(2) \emph{sampling}
gathers relevant samples 
for exhaustive model testing;
(3) \emph{test case generation} 
creates targeted test scenarios
based on properties and 
samples from the previous two stages; 
(4) \emph{testing graph analysis}  
conducts robustness assessments 
both locally, for an individual property,
and globally, across multiple properties, 
employing a probabilistic graph approach
to model their dependencies;
and, finally, (5) \emph{error summarisation} 
compiles and analyses 
recorded errors to generate 
actionable graphical 
reports and recommendations, 
thus guiding the refinement of models. 
My proposed framework
 not only fills existing gaps in DNN testing but 
also supports the development of models that are correct 
across varied environmental conditions.

\clearpage

