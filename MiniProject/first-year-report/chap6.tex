% \chapter{References} % Ensures chapter numbering starts correctly
% Adjusting chapter title format for regular (numbered) chapters
\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries\centering}{\chaptertitlename\ \thechapter}{20pt}{\Huge}

% Using similar styling for unnumbered chapters but without "Chapter" prefix
\titleformat{name=\chapter,numberless}
  {\normalfont\huge\bfseries\centering}{}{0pt}{\Huge}

\titlespacing*{\chapter}{0pt}{50pt}{40pt} % Adjust vertical spacing before and after the title


\label{chp:5}
\begin{singlespace}
\begin{thebibliography}{}

% BACKGROUND

\bibitem{ZhaoXBanks}Zhao, X., Banks, A., Sharp, J., Robu, V., Flynn, D., Fisher, M., and Huang, X. (2020). A safety framework for critical systems utilising deep neural networks. In Computer Safety, Reliability, and Security: 39th International Conference, SAFECOMP 2020, Lisbon, Portugal, September 16–18, 2020, Proceedings 39 (pp. 244-259). Springer International Publishing.


\bibitem{LeCun}LeCun, Y., Bengio, Y. and Hinton, G., 2015. Deep learning. nature, 521(7553), pp.436-444.

\bibitem{HuangX}Huang, X., Kroening, D., Ruan, W., Sharp, J., Sun, Y., Thamo, E., Wu, M. and Yi, X., 2020. A survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability. Computer Science Review, 37, p.100270.

% robustness and correctness 

\bibitem{Goodfellow} Goodfellow, I. J., Shlens, J., \& Szegedy, C. (2015). Explaining and Harnessing Adversarial Examples. In Proceedings of the International Conference on Learning Representations (ICLR). Link to Paper

\bibitem{Carlini} Carlini, N., \& Wagner, D. (2017). Towards Evaluating the Robustness of Neural Networks. In Proceedings of the IEEE Symposium on Security and Privacy (SP).
   
\bibitem{Sekhon} Sekhon, Jasmine, and Cody Fleming. Towards improved testing for deep learning.2019 IEEE/ACM 41st International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER). IEEE, 2019.

\bibitem{Rushby}Rushby, J. (2015). The interpretation and evaluation of assurance cases. Technical report, SRI International.

%LITERATURE


 \bibitem{dnn_archi}Liu, W., Wang, Z., Liu, X., Zeng, N., Liu, Y. and Alsaadi, F.E., 2017. A survey of deep neural network architectures and their applications. Neurocomputing, 234, pp.11-26.    \bibitem{Hassija}Hassija, V., Chamola, V., Mahapatra, A., Singal, A., Goel, D., Huang, K., Scardapane, S., Spinelli, I., Mahmud, M. and Hussain, A., 2024. Interpreting black-box models: a review on explainable artificial intelligence. Cognitive Computation, 16(1), pp.45-74.
 \bibitem{Liang}Liang, Y., Li, S., Yan, C., Li, M. and Jiang, C., 2021. Explaining the black-box model: A survey of local interpretation methods for deep neural networks. Neurocomputing, 419, pp.168-182.

 \bibitem{Biggio} Biggio, B. and Roli, F., 2018, October. Wild patterns: Ten years after the rise of adversarial machine learning. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security (pp. 2154-2156).

 \bibitem{poisonattack}
 Biggio, B., Nelson, B. and Laskov, P., 2012. Poisoning attacks against support vector machines. arXiv preprint arXiv:1206.6389.


 \bibitem{Badnets}
 Gu, T., Liu, K., Dolan-Gavitt, B. and Garg, S., 2019. Badnets: Evaluating backdooring attacks on deep neural networks. IEEE Access, 7, pp.47230-47244.
 \bibitem{evasion}
 Biggio, B., Corona, I., Maiorca, D., Nelson, B., Srndic, N., Laskov, P., Giacinto, G. and Roli, F., 2013. Evasion attacks against machine learning at test time. In Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2013, Prague, Czech Republic, September 23-27, 2013, Proceedings, Part III 13 (pp. 387-402). Springer Berlin Heidelberg.

 \bibitem{Chakraborty} 
 Chakraborty, A., Alam, M., Dey, V., Chattopadhyay, A. and Mukhopadhyay, D., 2018. Adversarial attacks and defences: A survey. arXiv preprint arXiv:1810.00069.

 \bibitem{FGSM} 
 Goodfellow, I.J., Shlens, J. and Szegedy, C., 2014. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572.  


 \bibitem{BIM} 
 Kurakin, A., Goodfellow, I. and Bengio, S., 2016. Adversarial machine learning at scale. arXiv preprint arXiv:1611.01236.

 \bibitem{CarliniWagner} 
 Carlini, N. and Wagner, D., 2017, May. Towards evaluating the robustness of neural networks. In 2017 ieee symposium on security and privacy (sp) (pp. 39-57). Ieee.

 \bibitem{deepfool} 
 Moosavi-Dezfooli, S.M., Fawzi, A. and Frossard, P., 2016. Deepfool: a simple and accurate method to fool deep neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2574-2582).

 \bibitem{JSMA}
 Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B. and Swami, A., 2016, March. The limitations of deep learning in adversarial settings. In 2016 IEEE European symposium on security and privacy (EuroS\&P) (pp. 372-387). IEEE.

\bibitem{Hosseini}
Hosseini, H. and Poovendran, R., 2018. Semantic adversarial examples. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (pp. 1614-1619).

\bibitem{adv_attacks}Ren, K., Zheng, T., Qin, Z. and Liu, X., 2020. Adversarial attacks and defenses in deep learning. Engineering, 6(3), pp.346-360.

\bibitem{deeptest}Tian, Y., Pei, K., Jana, S. and Ray, B., 2018, May. Deeptest: Automated testing of deep-neural-network-driven autonomous cars. In Proceedings of the 40th international conference on software engineering (pp. 303-314).


\bibitem{Engstrom}Engstrom, L., Tran, B., Tsipras, D., Schmidt, L. and Madry, A., 2017. A rotation and a translation suffice: Fooling cnns with simple transformations.

\bibitem{Pei}Pei, K., Zhu, L., Cao, Y., Yang, J., Vondrick, C. and Jana, S., 2017. Towards practical verification of machine learning: The case of computer vision systems. arXiv preprint arXiv:1712.01785.

  
\bibitem{deepxplore} Pei, K., Cao, Y., Yang, J. and Jana, S., 2017, October. Deepxplore: Automated whitebox testing of deep learning systems. In proceedings of the 26th Symposium on Operating Systems Principles (pp. 1-18).

\bibitem{Wicker} Wicker, M., Huang, X., and Kwiatkowska, M. (2018). Feature-guided black-box safety testing of deep neural networks. In Interna- tional Conference on Tools and Algorithms for the Construction and Analysis of Systems, pages 408–426. Springer.

\bibitem{Ma} Ma, L., Juefei-Xu, F., Sun, J., Chen, C., Su, T., Zhang, F., Xue, M., Li, B., Li, L., Liu, Y., Zhao, J., and Wang, Y. (2018). DeepGauge: Comprehensive and multi-granularity testing criteria for gauging the robustness of deep learning systems. In Automated Software Engineering (ASE), 33rd IEEE/ACM International Conference on.

    
\bibitem{SunY}Sun, Y., Huang, X., Kroening, D., Sharp, J., Hill, M. and Ashmore, R., 2018. Testing deep neural networks. arXiv preprint arXiv:1803.04792.

\bibitem{Sun} Sun, Y., Huang, X., Kroening, D., Sharp, J., Hill, M., and Ashmore, R. (2019). Structural test coverage criteria for deep neural networks. ACM Trans. Embed. Comput. Syst., 18(5s).

\bibitem{Cheng}Cheng, C.-H., Huang, C.-H., and Yasuoka, H.. Quantitative projection coverage for testing ML-enabled autonomous systems. In International Symposium on Automated Technology for Verification and Analysis. Springer.

\bibitem{Kim} Kim, J., Feldt, R., and Yoo, S. (2018b). Guiding deep learning system testing using surprise adequacy. arXiv preprint arXiv:1808.08444

\bibitem{Concolic} Sun, Y., Wu, M., Ruan, W., Huang, X., Kwiatkowska, M., and Kroening, D. (2018). Concolic testing for deep neural networks. In Automated Software Engineering (ASE), 33rd IEEE/ACM International Con- ference on.

\bibitem{Deepconcolic} Sun, Y., Huang, X., Kroening, D., Sharp, J., Hill, M., and Ashmore, R. (2019). Deepconcolic: testing and debugging deep neural net- works. In 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion), pages 111–114. IEEE.

\bibitem{tensorfuzz} Odena, A., Olsson, C., Andersen, D. and Goodfellow, I., 2019, May. Tensorfuzz: Debugging neural networks with coverage-guided fuzzing. In International Conference on Machine Learning (pp. 4901-4911). PMLR.

\bibitem{Deephunter}Xie, X., Ma, L., Juefei-Xu, F., Chen, H., Xue, M., Li, B., Liu, Y., Zhao, J., Yin, J. and See, S., 2018. Deephunter: Hunting deep neural network defects via coverage-guided fuzzing. arXiv preprint arXiv:1809.01266.

\bibitem{DLFuzz} Guo, J., Jiang, Y., Zhao, Y., Chen, Q., and Sun, J. (2018). DLFuzz: Differential fuzzing testing of deep learning systems. In Proceedings of the 2018 12nd Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2018.

\bibitem{Gopinath} Gopinath, D., Wang, K., Zhang, M., Pasareanu, C. S., and Khurshid, S. (2018). Symbolic execution for deep neural networks. arXiv preprint arXiv:1807.10439.

\bibitem{Agarwal} Agarwal, A., Lohia, P., Nagar, S., Dey, K., and Saha, D. (2018). Automated test generation to detect individual discrimination in ai
models. arXiv preprint arXiv:1809.03260.

\bibitem{Zhang} Zhang, M., Zhang, Y., Zhang, L., Liu, C., and Khurshid, S. (2018). DeepRoad: GAN-based metamorphic autonomous driving sys- tem testing. In Automated Software Engineering (ASE), 33rd IEEE/ACM International Conference on.
\bibitem{MODE} Ma, S., Liu, Y., Zhang, X., Lee, W.-C., and Grama, A. (2018). MODE: Automated neural network model debugging via state differential analysis and input selection. In Proceedings of the 12nd Joint Meeting on Foundations of Software Engineering. ACM.

\bibitem{Deepmutation}Hu, Q., Ma, L., Xie, X., Yu, B., Liu, Y. and Zhao, J., 2019, November. Deepmutation++: A mutation testing framework for deep learning systems. In 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE) (pp. 1158-1161). IEEE.

\bibitem{Braiek}Braiek, H.B. and Khomh, F., 2020. On testing machine learning programs. Journal of Systems and Software, 164, p.110542.


%Specification 
\bibitem{Scenic} Fremont, D.J., Dreossi, T., Ghosh, S., Yue, X., Sangiovanni-Vincentelli, A.L. and Seshia, S.A., 2019, June. Scenic: a language for scenario specification and scene generation. In Proceedings of the 40th ACM SIGPLAN conference on programming language design and implementation (pp. 63-78).



%SHAP
\bibitem{Fidel}Fidel, G., Bitton, R. and Shabtai, A., 2020, July. When explainability meets adversarial learning: Detecting adversarial examples using shap signatures. In 2020 international joint conference on neural networks (IJCNN) (pp. 1-8). IEEE.
\bibitem{Lin}Lin, Y.C. and Yu, F., 2023, May. DeepSHAP summary for adversarial example detection. In 2023 IEEE/ACM International Workshop on Deep Learning for Testing and Testing for Deep Learning (DeepTest) (pp. 17-24). IEEE.
\bibitem{Walker}
Walker, C., Simon, D., Jha, S.K. and Ewetz, R., 2023, October. Adversarial Pixel and Patch Detection Using Attribution Analysis. In MILCOM 2023-2023 IEEE Military Communications Conference (MILCOM) (pp. 710-715). IEEE.
\bibitem{Rahnama}
Rahnama, A. and Tseng, A., 2021. An adversarial approach for explaining the predictions of deep neural networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 3253-3262).
\bibitem{Watson}
Watson, M. and Al Moubayed, N., 2021, January. Attack-agnostic adversarial detection on medical data using explainable machine learning. In 2020 25th International Conference on Pattern Recognition (ICPR) (pp. 8180-8187). IEEE.
\bibitem{Kuppa}Kuppa, A. and Le-Khac, N.A., 2020, July. Black box attacks on explainable artificial intelligence (XAI) methods in cyber security. In 2020 International Joint Conference on neural networks (IJCNN) (pp. 1-8). IEEE.
\bibitem{Stiff}Stiff, H., 2019. Explainable AI as a Defence Mechanism for Adversarial Examples.




\bibitem{Dola}
Dola, S., Dwyer, M.B. and Soffa, M.L., 2021, May. Distribution-aware testing of neural networks using generative models. In 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE) (pp. 226-237). IEEE.

\bibitem{Sayah}
Sayah, M., Guebli, D., Al Masry, Z. and Zerhouni, N., 2021. Robustness testing framework for RUL prediction Deep LSTM networks. ISA transactions, 113, pp.28-38.

\bibitem{ChenJ}
Chen, J., Liang, Y., Shen, Q., Jiang, J. and Li, S., 2023. Toward understanding deep learning framework bugs. ACM Transactions on Software Engineering and Methodology, 32(6), pp.1-31.

% sampling

    \bibitem{Stratifiedsampling} Wu, Z., Wang, Z., Chen, J., You, H., Yan, M. and Wang, L., 2024. Stratified random sampling for neural network test input selection. Information and Software Technology, 165, p.107331.
    \bibitem{Han2005} Han, H., Wang, W.-Y., \& Mao, B.-H. (2005). Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning. In Advances in Intelligent Computing, ICIC 2005 (pp. 878-887). Springer.

    \bibitem{He2008} He, H., Bai, Y., Garcia, E. A., \& Li, S. (2008). ADASYN: Adaptive Synthetic Sampling Approach for Imbalanced Learning. In 2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)(pp. 1322-1328). IEEE.
    \bibitem{near-miss} Akira Tanimoto, So Yamada, Takashi Takenouchi, Masashi Sugiyama, Hisashi Kashima, Improving imbalanced classification using near-miss instances,Expert Systems with Applications, 201, 2022, 117130, ISSN 0957-4174, 
    \bibitem{Roth2019} Roth, K., Kilcher, Y., \& Hofmann, T. (2019). Adversarial Training for Weakly Supervised Learning. In \textit{Advances in Neural Information Processing Systems} (Vol. 32).








% % test and verification
%     \bibitem{Albarghouthi}
%     Aws Albarghouthi, Introduction to Neural Network Verification,2021.
    
%     \bibitem{DeepMind2023}
%     DeepMind Safety Research, Towards Robust and Verified AI: Specification Testing, Robust Training, and Formal Verification.

%     \bibitem{Urban2021}
%     Caterina Urban, et al., A Review of Formal Methods applied to Machine Learning,2021.

    






% \bibitem{Agarwal} Agarwal, Aniya, et al. "Automated test generation to detect individual discrimination in AI models." arXiv preprint arXiv:1809.03260 (2018).

% \bibitem{Youcheng} Sun, Youcheng, et al. "Concolic testing for deep neural networks." Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. 2018.

% \bibitem{Kexin} Pei, Kexin, et al. "DeepXplore." Communications of the ACM 62.11 (2019): 137-145.

% \bibitem{Yuchi} Tian, Yuchi, et al. "Deeptest: Automated testing of deep-neural-network-driven autonomous cars." Proceedings of the 40th international conference on software engineering. 2018.

% \bibitem{Sun} Sun, Youcheng, et al. "Testing deep neural networks." arXiv preprint arXiv:1803.04792 (2018).


% \bibitem{Zhang} Zhang, Mengshi, et al. "DeepRoad: GAN-based metamorphic testing and input validation framework for autonomous driving systems." Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. 2018.

% \bibitem{Xie} Xie, Xiaofei, et al. "Deephunter: Hunting deep neural network defects via coverage-guided fuzzing." arXiv preprint arXiv:1809.01266 (2018).

% \bibitem{Gopinath}	Gopinath, Divya, et al. "Symbolic execution for deep neural networks." arXiv preprint arXiv:1807.10439 (2018).

% \bibitem{DeRaedt}
% De Raedt, L., Kimmig, A. and Toivonen, H., 2007, January. Problog: A probabilistic prolog and its application in link discovery. In IJCAI (Vol. 7, pp. 2462-2467).

% \bibitem{DeepProbLog}
% Manhaeve, R., Dumancic, S., Kimmig, A., Demeester, T. and De Raedt, L., 2018. Deepproblog: Neural probabilistic logic programming. Advances in neural information processing systems, 31.
% \bibitem{Sato1997} Sato, T., Kameya, Y.: PRISM: A symbolic-statistical modeling language. In: IJCAI. pp. 1330--1339 (1997)

% \bibitem{Koller2009} Koller, D., Friedman, N.: Probabilistic Graphical Models: Principles and Techniques. MIT Press (2009)

% \bibitem{Vennekens2004} Vennekens, J., Denecker, M., Bruynooghe, M.: Logic programs with annotated disjunctions. In: ICLP. pp. 195--209 (2004)

% \bibitem{DeRaedt2007} De Raedt, L., Kimmig, A., Toivonen, H.: ProbLog: A probabilistic Prolog and its application in link discovery. In: IJCAI. pp. 2462--2467 (2007)

% \bibitem{Poole1993} Poole, D.: Probabilistic Horn abduction and Bayesian networks. Artificial Intelligence 64(1), 81--129 (1993)

% \bibitem{Poole1997} Poole, D.: The independent choice logic for modelling multiple agents under uncertainty. Artificial Intelligence 94(1-2), 7--56 (1997)

% \bibitem{Sato2001} Sato, T.: A statistical learning method for logic programs with distribution semantics. In: ICLP. pp. 217--232 (2001)

% \bibitem{Kimmig2011} Kimmig, A., Demoen, B., De Raedt, L., Costa, V.S., Rocha, R.: On the implementation of the probabilistic logic programming language ProbLog. Theory and Practice of Logic Programming 11(2-3), 235--262 (2011)

% \bibitem{Vidal2023} Vidal, G.: Explanations as Programs in Probabilistic Logic Programming. In: Hanus, M., Igarashi, A. (eds) Functional and Logic Programming. FLOPS 2022. Lecture Notes in Computer Science, vol 13215. Springer, Cham (2023)

% \bibitem{Arrieta2020} Arrieta, A.B., Rodríguez, N.D., Ser, J.D., et al.: Explainable artificial intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information Fusion 58, 82--115 (2020)

\end{thebibliography}
\bibliographystyle{plain}
\end{singlespace}
