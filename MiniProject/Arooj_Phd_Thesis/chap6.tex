% \chapter{References} % Ensures chapter numbering starts correctly
% Adjusting chapter title format for regular (numbered) chapters
\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries\centering}{\chaptertitlename\ \thechapter}{20pt}{\Huge}

% Using similar styling for unnumbered chapters but without "Chapter" prefix
\titleformat{name=\chapter,numberless}
  {\normalfont\huge\bfseries\centering}{}{0pt}{\Huge}

\titlespacing*{\chapter}{0pt}{50pt}{40pt} % Adjust vertical spacing before and after the title


\label{chp:5}
\begin{singlespace}
\begin{thebibliography}{}

% BACKGROUND

\bibitem{ZhaoXBanks}Zhao, X., Banks, A., Sharp, J., Robu, V., Flynn, D., Fisher, M., and Huang, X. (2020). A safety framework for critical systems utilising deep neural networks. In Computer Safety, Reliability, and Security: 39th International Conference, SAFECOMP 2020, Lisbon, Portugal, September 16–18, 2020, Proceedings 39 (pp. 244-259). Springer International Publishing.


\bibitem{LeCun}LeCun, Y., Bengio, Y. and Hinton, G., 2015. Deep learning. nature, 521(7553), pp.436-444.

\bibitem{HuangX}Huang, X., Kroening, D., Ruan, W., Sharp, J., Sun, Y., Thamo, E., Wu, M. and Yi, X., 2020. A survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability. Computer Science Review, 37, p.100270.

% robustness and correctness 

\bibitem{Goodfellow} Goodfellow, I. J., Shlens, J., \& Szegedy, C. (2015). Explaining and Harnessing Adversarial Examples. In Proceedings of the International Conference on Learning Representations (ICLR). Link to Paper

\bibitem{Carlini} Carlini, N., \& Wagner, D. (2017). Towards Evaluating the Robustness of Neural Networks. In Proceedings of the IEEE Symposium on Security and Privacy (SP).
   
\bibitem{Sekhon} Sekhon, Jasmine, and Cody Fleming. "Towards improved testing for deep learning." 2019 IEEE/ACM 41st International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER). IEEE, 2019.

\bibitem{Rushby}Rushby, J. (2015). The interpretation and evaluation of assurance cases. Technical report, SRI International.

%LITERATURE


 \bibitem{dnn_archi}Liu, W., Wang, Z., Liu, X., Zeng, N., Liu, Y. and Alsaadi, F.E., 2017. A survey of deep neural network architectures and their applications. Neurocomputing, 234, pp.11-26.    \bibitem{Hassija}Hassija, V., Chamola, V., Mahapatra, A., Singal, A., Goel, D., Huang, K., Scardapane, S., Spinelli, I., Mahmud, M. and Hussain, A., 2024. Interpreting black-box models: a review on explainable artificial intelligence. Cognitive Computation, 16(1), pp.45-74.
 \bibitem{Liang}Liang, Y., Li, S., Yan, C., Li, M. and Jiang, C., 2021. Explaining the black-box model: A survey of local interpretation methods for deep neural networks. Neurocomputing, 419, pp.168-182.

 \bibitem{Biggio} Biggio, B. and Roli, F., 2018, October. Wild patterns: Ten years after the rise of adversarial machine learning. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security (pp. 2154-2156).

 \bibitem{poisonattack}
 Biggio, B., Nelson, B. and Laskov, P., 2012. Poisoning attacks against support vector machines. arXiv preprint arXiv:1206.6389.


 \bibitem{Badnets}
 Gu, T., Liu, K., Dolan-Gavitt, B. and Garg, S., 2019. Badnets: Evaluating backdooring attacks on deep neural networks. IEEE Access, 7, pp.47230-47244.
 \bibitem{evasion}
 Biggio, B., Corona, I., Maiorca, D., Nelson, B., Šrndić, N., Laskov, P., Giacinto, G. and Roli, F., 2013. Evasion attacks against machine learning at test time. In Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2013, Prague, Czech Republic, September 23-27, 2013, Proceedings, Part III 13 (pp. 387-402). Springer Berlin Heidelberg.

 \bibitem{Chakraborty} 
 Chakraborty, A., Alam, M., Dey, V., Chattopadhyay, A. and Mukhopadhyay, D., 2018. Adversarial attacks and defences: A survey. arXiv preprint arXiv:1810.00069.

 \bibitem{FGSM} 
 Goodfellow, I.J., Shlens, J. and Szegedy, C., 2014. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572.  


 \bibitem{BIM} 
 Kurakin, A., Goodfellow, I. and Bengio, S., 2016. Adversarial machine learning at scale. arXiv preprint arXiv:1611.01236.

 \bibitem{CarliniWagner} 
 Carlini, N. and Wagner, D., 2017, May. Towards evaluating the robustness of neural networks. In 2017 ieee symposium on security and privacy (sp) (pp. 39-57). Ieee.

 \bibitem{deepfool} 
 Moosavi-Dezfooli, S.M., Fawzi, A. and Frossard, P., 2016. Deepfool: a simple and accurate method to fool deep neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2574-2582).

 \bibitem{JSMA}
 Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.B. and Swami, A., 2016, March. The limitations of deep learning in adversarial settings. In 2016 IEEE European symposium on security and privacy (EuroS\&P) (pp. 372-387). IEEE.

\bibitem{Hosseini}
Hosseini, H. and Poovendran, R., 2018. Semantic adversarial examples. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (pp. 1614-1619).

\bibitem{adv_attacks}Ren, K., Zheng, T., Qin, Z. and Liu, X., 2020. Adversarial attacks and defenses in deep learning. Engineering, 6(3), pp.346-360.

\bibitem{deeptest}Tian, Y., Pei, K., Jana, S. and Ray, B., 2018, May. Deeptest: Automated testing of deep-neural-network-driven autonomous cars. In Proceedings of the 40th international conference on software engineering (pp. 303-314).


\bibitem{Engstrom}Engstrom, L., Tran, B., Tsipras, D., Schmidt, L. and Madry, A., 2017. A rotation and a translation suffice: Fooling cnns with simple transformations.

\bibitem{Pei}Pei, K., Zhu, L., Cao, Y., Yang, J., Vondrick, C. and Jana, S., 2017. Towards practical verification of machine learning: The case of computer vision systems. arXiv preprint arXiv:1712.01785.

  
\bibitem{deepxplore} Pei, K., Cao, Y., Yang, J. and Jana, S., 2017, October. Deepxplore: Automated whitebox testing of deep learning systems. In proceedings of the 26th Symposium on Operating Systems Principles (pp. 1-18).

\bibitem{Wicker et al., 2018} Wicker, M., Huang, X., and Kwiatkowska, M. (2018). Feature-guided black-box safety testing of deep neural networks. In Interna- tional Conference on Tools and Algorithms for the Construction and Analysis of Systems, pages 408–426. Springer.

\bibitem{Ma et al., 2018} Ma, L., Juefei-Xu, F., Sun, J., Chen, C., Su, T., Zhang, F., Xue, M., Li, B., Li, L., Liu, Y., Zhao, J., and Wang, Y. (2018). DeepGauge: Comprehensive and multi-granularity testing criteria for gauging the robustness of deep learning systems. In Automated Software Engineering (ASE), 33rd IEEE/ACM International Conference on.

    
\bibitem{SunY}Sun, Y., Huang, X., Kroening, D., Sharp, J., Hill, M. and Ashmore, R., 2018. Testing deep neural networks. arXiv preprint arXiv:1803.04792.

\bibitem{Sun et al., 2019} Sun, Y., Huang, X., Kroening, D., Sharp, J., Hill, M., and Ashmore, R. (2019). Structural test coverage criteria for deep neural networks. ACM Trans. Embed. Comput. Syst., 18(5s).

\bibitem{Cheng et al., 2018}Cheng, C.-H., Huang, C.-H., and Yasuoka, H.. Quantitative projection coverage for testing ML-enabled autonomous systems. In International Symposium on Automated Technology for Verification and Analysis. Springer.

\bibitem{Kim et al., 2018} Kim, J., Feldt, R., and Yoo, S. (2018b). Guiding deep learn- ing system testing using surprise adequacy. arXiv preprint arXiv:1808.08444
\bibitem{Concolic} Sun, Y., Wu, M., Ruan, W., Huang, X., Kwiatkowska, M., and Kroening, D. (2018). Concolic testing for deep neural networks. In Automated Software Engineering (ASE), 33rd IEEE/ACM International Con- ference on.
\bibitem{Deepconcolic} Sun, Y., Huang, X., Kroening, D., Sharp, J., Hill, M., and Ashmore, R. (2019). Deepconcolic: testing and debugging deep neural net- works. In 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion), pages 111–114. IEEE.

\bibitem{tensorfuzz} Odena, A., Olsson, C., Andersen, D. and Goodfellow, I., 2019, May. Tensorfuzz: Debugging neural networks with coverage-guided fuzzing. In International Conference on Machine Learning (pp. 4901-4911). PMLR.

\bibitem{Deephunter}Xie, X., Ma, L., Juefei-Xu, F., Chen, H., Xue, M., Li, B., Liu, Y., Zhao, J., Yin, J. and See, S., 2018. Deephunter: Hunting deep neural network defects via coverage-guided fuzzing. arXiv preprint arXiv:1809.01266.

\bibitem{DLFuzz} Guo, J., Jiang, Y., Zhao, Y., Chen, Q., and Sun, J. (2018). DLFuzz: Differential fuzzing testing of deep learning systems. In Proceedings of the 2018 12nd Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2018.

\bibitem{Gopinath et al., 2018} Gopinath, D., Wang, K., Zhang, M., Pasareanu, C. S., and Khurshid, S. (2018). Symbolic execution for deep neural networks. arXiv preprint arXiv:1807.10439.

\bibitem{Agarwal et al., 2018} Agarwal, A., Lohia, P., Nagar, S., Dey, K., and Saha, D. (2018). Automated test generation to detect individual discrimination in ai
models. arXiv preprint arXiv:1809.03260.

\bibitem{Zhang et al., 2018} Zhang, M., Zhang, Y., Zhang, L., Liu, C., and Khurshid, S. (2018). DeepRoad: GAN-based metamorphic autonomous driving sys- tem testing. In Automated Software Engineering (ASE), 33rd IEEE/ACM International Conference on.
\bibitem{MODE} Ma, S., Liu, Y., Zhang, X., Lee, W.-C., and Grama, A. (2018). MODE: Automated neural network model debugging via state differential analysis and input selection. In Proceedings of the 12nd Joint Meeting on Foundations of Software Engineering. ACM.

% sampling
    \bibitem{Frey1997} Frey, B. J., \& Fisher, D. H. (1997). Modeling Decision Tree Performance with the Power Law. In \textit{Proceedings of the Fourteenth International Conference on Machine Learning} (pp. 59-65).
    \bibitem{Katz2017} Katz, G., Barrett, C., Dill, D. L., Julian, K., \& Kochenderfer, M. J. (2017). Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks. In \textit{Proceedings of the 29th International Conference on Computer Aided Verification} (pp. 97-117).
    \bibitem{Chawla2002} Chawla, N. V., Bowyer, K. W., Hall, L. O., \& Kegelmeyer, W. P. (2002). SMOTE: Synthetic Minority Over-sampling Technique. \textit{Journal of Artificial Intelligence Research}, 16, 321-357.
    \bibitem{He2008} He, H., Bai, Y., Garcia, E. A., \& Li, S. (2008). ADASYN: Adaptive Synthetic Sampling Approach for Imbalanced Learning. In \textit{2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)} (pp. 1322-1328). IEEE.
    \bibitem{Mani2003} Mani, I., \& Zhang, I. (2003). kNN approach to unbalanced data distributions: a case study involving information extraction. In \textit{Proceedings of Workshop on Learning from Imbalanced Datasets} (Vol. 126).
    \bibitem{Han2005} Han, H., Wang, W.-Y., \& Mao, B.-H. (2005). Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning. In \textit{Advances in Intelligent Computing, ICIC 2005} (pp. 878-887). Springer.
    \bibitem{Roth2019} Roth, K., Kilcher, Y., \& Hofmann, T. (2019). Adversarial Training for Weakly Supervised Learning. In \textit{Advances in Neural Information Processing Systems} (Vol. 32).


   
  
  


    \bibitem{KimJ}Kim, J., Feldt, R. and Yoo, S., 2019, May. Guiding deep learning system testing using surprise adequacy. In 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE) (pp. 1039-1049). IEEE.
  
   
    \bibitem{dlfuzz}Guo, J., Jiang, Y., Zhao, Y., Chen, Q. and Sun, J., 2018, October. Dlfuzz: Differential fuzzing testing of deep learning systems. In Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (pp. 739-743).





% test and verification
    \bibitem{Albarghouthi}
    Aws Albarghouthi, Introduction to Neural Network Verification,2021.
    
    \bibitem{DeepMind2023}
    DeepMind Safety Research, Towards Robust and Verified AI: Specification Testing, Robust Training, and Formal Verification.

    \bibitem{Urban2021}
    Caterina Urban, et al., A Review of Formal Methods applied to Machine Learning,2021.

    






\bibitem{Agarwal} Agarwal, Aniya, et al. "Automated test generation to detect individual discrimination in AI models." arXiv preprint arXiv:1809.03260 (2018).

\bibitem{Youcheng} Sun, Youcheng, et al. "Concolic testing for deep neural networks." Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. 2018.

\bibitem{Kexin} Pei, Kexin, et al. "DeepXplore." Communications of the ACM 62.11 (2019): 137-145.

\bibitem{Yuchi} Tian, Yuchi, et al. "Deeptest: Automated testing of deep-neural-network-driven autonomous cars." Proceedings of the 40th international conference on software engineering. 2018.

\bibitem{Sun} Sun, Youcheng, et al. "Testing deep neural networks." arXiv preprint arXiv:1803.04792 (2018).

\bibitem{Ma} Ma, Lei, et al. "Deepgauge: Multi-granularity testing criteria for deep learning systems." Proceedings of the 33rd ACM/IEEE international conference on automated software engineering. 2018.

\bibitem{Zhang} Zhang, Mengshi, et al. "DeepRoad: GAN-based metamorphic testing and input validation framework for autonomous driving systems." Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. 2018.

\bibitem{Xie} Xie, Xiaofei, et al. "Deephunter: Hunting deep neural network defects via coverage-guided fuzzing." arXiv preprint arXiv:1809.01266 (2018).

\bibitem{Gopinath}	Gopinath, Divya, et al. "Symbolic execution for deep neural networks." arXiv preprint arXiv:1807.10439 (2018).

% \bibitem{DeRaedt}
% De Raedt, L., Kimmig, A. and Toivonen, H., 2007, January. Problog: A probabilistic prolog and its application in link discovery. In IJCAI (Vol. 7, pp. 2462-2467).

% \bibitem{DeepProbLog}
% Manhaeve, R., Dumancic, S., Kimmig, A., Demeester, T. and De Raedt, L., 2018. Deepproblog: Neural probabilistic logic programming. Advances in neural information processing systems, 31.
\bibitem{Sato1997} Sato, T., Kameya, Y.: PRISM: A symbolic-statistical modeling language. In: IJCAI. pp. 1330--1339 (1997)

\bibitem{Koller2009} Koller, D., Friedman, N.: Probabilistic Graphical Models: Principles and Techniques. MIT Press (2009)

\bibitem{Vennekens2004} Vennekens, J., Denecker, M., Bruynooghe, M.: Logic programs with annotated disjunctions. In: ICLP. pp. 195--209 (2004)

\bibitem{DeRaedt2007} De Raedt, L., Kimmig, A., Toivonen, H.: ProbLog: A probabilistic Prolog and its application in link discovery. In: IJCAI. pp. 2462--2467 (2007)

\bibitem{Poole1993} Poole, D.: Probabilistic Horn abduction and Bayesian networks. Artificial Intelligence 64(1), 81--129 (1993)

\bibitem{Poole1997} Poole, D.: The independent choice logic for modelling multiple agents under uncertainty. Artificial Intelligence 94(1-2), 7--56 (1997)

\bibitem{Sato2001} Sato, T.: A statistical learning method for logic programs with distribution semantics. In: ICLP. pp. 217--232 (2001)

\bibitem{Kimmig2011} Kimmig, A., Demoen, B., De Raedt, L., Costa, V.S., Rocha, R.: On the implementation of the probabilistic logic programming language ProbLog. Theory and Practice of Logic Programming 11(2-3), 235--262 (2011)

\bibitem{Vidal2023} Vidal, G.: Explanations as Programs in Probabilistic Logic Programming. In: Hanus, M., Igarashi, A. (eds) Functional and Logic Programming. FLOPS 2022. Lecture Notes in Computer Science, vol 13215. Springer, Cham (2023)

\bibitem{Arrieta2020} Arrieta, A.B., Rodríguez, N.D., Ser, J.D., et al.: Explainable artificial intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information Fusion 58, 82--115 (2020)

\end{thebibliography}
\bibliographystyle{plain}
\end{singlespace}
