% Adjusting chapter title format for regular (numbered) chapters
\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries\centering}{\chaptertitlename\ \thechapter}{20pt}{\Huge}

% Using similar styling for unnumbered chapters but without "Chapter" prefix
\titleformat{name=\chapter,numberless}
  {\normalfont\huge\bfseries\centering}{}{0pt}{\Huge}

\titlespacing*{\chapter}{0pt}{50pt}{40pt} % Adjust vertical spacing before and after the title

\chapter{Literature Review}
\label{chp:2}

\section{Overview}
This chapter provides a review of the literature related to deep neural networks, probabilistic logic programming, and their integration, particularly focusing on Problog and its extensions.

\subsection{Deep Neural Networks and AI Systems}

Deep neural networks (DNNs) mimic the structure of the human brain, consisting of millions of interconnected neurons. They extract high-level features from raw input using labeled training data without human interference.

Formally, a DNN is a function $f\colon\mathbb{R}^{s_0}\mapsto \mathbb{R}^{s_k}$ that takes as input a vector of size $s_0$ and produces a vector of size $s_k$. The function $f$ is computed by composing $k$ layers $L_1\colon\mathbb{R}^{s_0} \mapsto\mathbb{R}^{s_1}, \dots, L_k\colon\mathbb{R}^{s_{k-1}}\mapsto\mathbb{R}^{s_k}$ as $f(x) = L_k(\cdots L_2(L_1(x))\cdots)$.

Each layer~$L_i$ typically implements a non-linear function. For instance, a \emph{fully-connected} layer linearly transforms its input $x_{i-1}$ as $W x_{i-1} + b$, where $W\in\mathbb{R}^{s_{i} \times s_{i-1}}$ is the matrix of weights and $b\in\mathbb{R}^{s_i}$ is the bias vector. Then, it applies a non-linear activation function (e.g., sigmoid or Rectified Linear Unit (ReLU)) component-wise, generating the output vector $x_i$. The weights specify how its input neurons are connected to its output neurons and are known as \emph{DNN parameters}. For more information about DNNs, we refer the reader to \cite{dnn_archi, Hassija, Liang}.

The objective of DNN training is to learn parameters during training to make accurate predictions on unseen data during real-world deployment.

When the prediction task is classification, then $s_k$ represents the number of classes. Assuming that $f(x) = (y_1,\dots,y_{s_k})$, the \emph{classification result} is $\displaystyle\mathop{\text{argmax}}_{i=1}^{s_k} y_i$, which is the index of the component with the highest probability $y_i$. By abuse of notation, sometimes we write $f(x)=c$ to denote the fact that $x$ was classified as $c$. We also write $f(x)_c$ to refer to $y_c$ which represents the probability of $x$ being in class $c$.

By an \emph{AI system}, we refer to any software system capable of performing complex tasks through the use of data, algorithms, and high computational power, which typically require human intelligence. These tasks include problem-solving, reasoning, decision-making, and natural language understanding.

Deep learning is a subset of AI that utilizes deep neural networks (DNNs) for complex pattern recognition. Some AI systems are solely based on DNN components, whereas \emph{hybrid} AI systems combine DNNs with traditional software to produce the final output.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{traditionalandDNN.pdf}
    \caption{Comparison between program flows of a traditional program (left) and a neural network (right). The nodes in gray denote the corresponding basic blocks or neurons that participated while processing an input.}
    \label{fig:graph}
\end{figure}

\subsection{Robustness of DNNs}

Deep neural networks (DNNs) are known for their lack of robustness. Research has shown DNNs to be vulnerable to two main categories of adversaries: \emph{adversarial attacks}~\cite{adv_attacks} and \emph{image transformations}~\cite{deeptest}.

Let $\mathcal{A}$ denote an adversary. Each category can be described formally as follows:

\smallskip\noindent%
\textbf{Adversarial Attacks $\mathcal{A}_{\text{adv}}$}

(\adv) This involves the generation of perturbations $\delta$ such that $x' = x + \delta$ misleads the DNN $f$ into making incorrect predictions, where $x$ is the original input and $x'$ is the perturbed input. Various methods under this category include:

\begin{itemize}
    \item \emph{Fast Gradient Sign Method (FGSM)}: For an input~$x$ and its true label $y$, FGSM generates $x' = x + \epsilon \cdot \text{sign}(\nabla_x J(x, y))$, where $J$ is the loss function and $\epsilon$ is a small perturbation factor.
    \item \emph{Basic Iterative Method (BIM)}: This extends FGSM by iteratively applying small perturbations: $x'^{(i+1)} = x'^{(i)} + \alpha \cdot \text{sign}(\nabla_x J(x'^{(i)}, y))$.
    \item \emph{Carlini and Wagner (C\&W) Attack}: Utilizes optimization to find $\delta$ that minimizes the $L_p$-norm while ensuring $f(x + \delta) \neq y$.
    \item \emph{DeepFool}: Iteratively perturbs $x$ by $\delta$ to move it across decision boundaries.
    \item \emph{Jacobian-based Saliency Map Attack (JSMA)}: Manipulates specific features of $x$ to achieve targeted misclassifications.
\end{itemize}

\smallskip\noindent%
\textbf{Image Transformations $\mathcal{A}_{\text{trans}}$}

This involves modifying the input images in a manner that exploits the model's sensitivity to variations, potentially causing misclassifications. Various methods under this category include:

\begin{itemize}
    \item \emph{Noise Addition}: Introducing noise $\eta$ such that $x' = x + \eta$. We consider \emph{Gaussian} noise and \emph{salt-and-pepper} noise.
    \item \emph{Translation}: Shifting the image $x$ by a vector $t$ to obtain $x' = \text{translate}(x, t)$.
    \item \emph{Scaling}: Resizing the image $x$ by a factor $s$ to get $x' = \text{scale}(x, s)$.
    \item \emph{Shearing}: Applying a shear transformation to $x$ resulting in $x' = \text{shear}(x, \theta)$.
    \item \emph{Rotation}: Rotating the image $x$ by an angle $\theta$ to produce $x' = \text{rotate}(x, \theta)$.
    \item \emph{Contrast Adjustment}: Modifying the contrast of $x$, represented as $x' = \text{adjust\_contrast}(x, \alpha)$.
    \item \emph{Brightness Change}: Altering the brightness of $x$, yielding $x' = \text{change\_brightness}(x, \beta)$.
    \item \emph{Blurring}: Applying a blur effect to $x$, giving $x' = \text{blur}(x, k)$, where $k$ is the kernel size.
    \item \emph{Occlusion}: Partially hiding regions of $x$, leading to $x' = \text{occlude}(x, m)$, where $m$ denotes the mask.
\end{itemize}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{figures/output_update.png}
    \caption{Image transformations for ...}
    \label{fig:image-trans}
\end{figure*}

By analyzing various types of adversaries, our proposed comprehensive testing framework evaluates model robustness, providing probabilities of model effectiveness against each adversary and assessing accuracy under adversarial conditions across different classes within any dataset.

\subsection{DNN Testing Techniques}

The development of DNNs is significantly different from traditional software. While developers explicitly define logic in traditional software, DNNs learn logic rules from raw data. Developers shape these rules by modifying the training data, selecting features, and designing the DNN architecture, such as the number of neurons and layers.

Since the logic of a DNN is non-transparent \cite{deepxplore}, identifying the reasons behind its erroneous behavior is challenging. Therefore, testing and correcting its errors are crucial, particularly in safety-critical systems. Next, we briefly introduce two major DNN testing techniques: coverage criteria and test-case generation.

\smallskip\noindent%
\textbf{Coverage Criteria}

In traditional software testing, coverage criteria measure how thoroughly software is tested. In DNNs, coverage might not directly apply to lines of code but rather to the input space or the variety of data the model can effectively handle or provide predictions for.

Neuron coverage (NC) \cite{deepxplore} is the first coverage metric proposed in the literature to test DNNs. It is defined as the ratio of neurons activated by a test input to the total number of neurons in the model, where a neuron is activated when its activation value exceeds a predefined threshold.

Ma et al. \cite{deepguage} proposed a variety of coverage metrics, including K-multisection neuron coverage (KMNC), Neuron boundary coverage (NBC), and Strong neuron activation coverage (SNAC). KMNC calculates coverage by dividing the interval between lower and upper bounds into k-bins and measuring the number of bins activated by the test inputs. NBC measures the ratio of corner case regions covered by test inputs, with corner cases defined as activation values below or above those observed during training. SNAC similarly measures how many upper corner cases, defined as activation values above the training range, are covered by test inputs.

Modified Condition/Decision Coverage (MC/DC) \cite{SunY} captures causal changes in test inputs based on the sign and value change of a neuron's activation.

Likelihood-based Surprise Adequacy (LSA) uses Kernel Density Estimation (KDE) to estimate the likelihood of a test input during the training phase, prioritizing inputs with higher LSA scores as they are closer to classification boundaries. Distance-based Surprise Adequacy (DSA) is an alternative to LSA that uses the distance between activation traces of new test inputs and those observed during training \cite{KimJ}.

\smallskip\noindent%
\textbf{DNN Test-case Generation}

Test-case generation methods are influenced by traditional software testing methods like fuzz testing, metamorphic testing, and symbolic execution. In the following sections, we will explore the current state of the art in DNN test generation.

DeepXplore \cite{deepxplore} is a whitebox test-case generation method that checks how different DNNs behave using domain-specific rules on inputs. It uses multiple models trained on the same data to find differences in their prediction. It aims to jointly optimize neuron coverage and different predictions between models, using gradient ascent for test generation.

DeepTest \cite{deeptest} focuses on generating test inputs for autonomous cars by applying domain-specific rules on seed inputs. It uses a greedy search method based on the NC metric to create effective test cases.

Adapting traditional fuzzing techniques for DNN test-case generation includes methods like DLFuzz \cite{dlfuzz} and TensorFuzz \cite{tensorfuzz}. DLFuzz generates adversarial inputs based on NC, akin to DeepXplore, but does not require multiple models and uses constraints to keep new inputs similar to originals. TensorFuzz employs coverage-guided testing to uncover numerical issues and discrepancies in DNNs and their quantized versions.

DeepConcolic \cite{deepconcolic} employs a concolic testing approach to generate adversarial inputs for DNN testing. It combines symbolic execution with concrete execution path information to meet coverage criteria, supporting both NC and MC/DC criteria.

Traditional techniques are simple, failing to capture the full complexity and precision of model behaviors. Exploring all possible behaviors of a model is nearly impossible due to the vast number of paths to consider. These metrics also often overlook the detailed interactions within and between layers of the model. Defining and testing all necessary decision boundaries, especially in complex models, is a daunting task. Many existing metrics do not provide clear directions for improving the model, leaving you without actionable insights. Scalability and adaptability are other major issues. Many criteria are not scalable or adaptable across diverse model architectures.

In this thesis, we address these issues and design a systematic testing framework for DNNs.

\subsection{Bayesian Networks}

Bayesian networks are a powerful probabilistic graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG). They are particularly useful for modeling uncertainty in complex systems. The fundamental equation of Bayesian networks is Bayes' theorem, which is given by:

\begin{equation}
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
\end{equation}

This equation allows us to update the probability estimate for a hypothesis as more evidence or information becomes available.

In the context of DNNs, Bayesian networks can offer significant advantages. Behavioral assessment considers probabilistic relationships to offer a richer, more detailed understanding of how different inputs affect model outputs. By developing a strategic focus on high-risk areas, it prioritizes regions with the highest uncertainty or risk for targeted testing, making the process more efficient and effective.


% Start of Problog integration
\subsection{Probabilistic Logic Programming and Problog}
{\color{blue}
Probabilistic logic programming (PLP) combines logic programming with probability theory, enabling the representation of uncertain knowledge. Problog, a prominent PLP language, extends Prolog by associating probabilities with facts and rules, facilitating the handling of uncertain information effectively.

Problog was introduced by De Raedt et al. \cite{DeRaedt}, providing a framework for probabilistic reasoning within the well-established logical framework of Prolog. The key contributions of Problog include:
\begin{itemize}
    \item \textbf{Integration of Probabilities:} Problog integrates probabilistic reasoning with logic programming by allowing facts to have associated probabilities.
    \item \textbf{Flexible Inference Mechanism:} It supports various inference techniques, including exact and approximate inference, to handle different types of queries and data efficiently.
    \item \textbf{Expressiveness:} Problog's expressiveness allows it to model complex relationships and dependencies, making it suitable for a wide range of applications.
\end{itemize}
}

% Prolog to Python Syntax Table
\subsection{Prolog to Python Syntax Conversion}

Clauses in Problog can be constructed by overloading Python operators, making the syntax more intuitive for those familiar with Python. The following table illustrates the conversion:

\begin{table}[h]
  \centering
  \begin{tabular}{|l|l|l|}
  \hline
  \textbf{Prolog} & \textbf{Python} & \textbf{English} \\
  \hline
  :- & \texttt{<<} & clause \\
  ,  & \texttt{\&} & and \\
  ;  & \texttt{|} & or \\
  \textbackslash+ & \texttt{\textasciitilde} & not \\
  \hline
  \end{tabular}
  \caption{Prolog to Python Syntax Conversion}
  \label{table:prolog-python-syntax}
  \end{table}
  
  
% Example Scenario
\subsection{Example Scenario}


In this section, we illustrate how Problog can be utilized to find global robustness based on local robustness values obtained from a deep learning model.

Consider a scenario where we have the local robustness values for two digits, digit 0 and digit 1, obtained using a deep learning model in Python. We use Problog to find the global robustness based on these local values.

Here is an example Problog code snippet:

\begin{verbatim}
0.8::digit_0.
0.6::digit_1.

correct_0 :- digit_0.
wrong_0 :- \+correct_0.
correct_1 :- digit_1.
wrong_1 :- \+correct_1.

pair_0_1 :- correct_0, correct_1.
pair_wrong_0_1 :- wrong_0, wrong_1.

global_correct :- pair_0_1; pair_wrong_0_1.

query(correct_0).
query(correct_1).
query(wrong_0).
query(wrong_1).
query(pair_0_1).
query(pair_wrong_0_1).
query(global_correct).
\end{verbatim}

In this example:
\begin{itemize}
  \item \texttt{0.8::digit\_0.} specifies that digit 0 has a local robustness probability of 0.8.
  \item \texttt{0.6::digit\_1.} specifies that digit 1 has a local robustness probability of 0.6.
  \item \texttt{correct\_0} and \texttt{correct\_1} indicate that the predictions for digits 0 and 1 are correct.
  \item \texttt{wrong\_0} and \texttt{wrong\_1} indicate that the predictions for digits 0 and 1 are wrong.
  \item \texttt{pair\_0\_1} checks if both digits are correctly predicted.
  \item \texttt{pair\_wrong\_0\_1} checks if both digits are wrongly predicted.
  \item \texttt{global\_correct} determines if the global prediction is correct by checking if both digits are either correctly or wrongly predicted.
  \item The \texttt{query} statements are used to query the probabilities of these events.
\end{itemize}


Using Problog in this way allows us to compute the global robustness of the system based on the local robustness of individual components, providing a more comprehensive assessment of the model's performance under uncertainty.


