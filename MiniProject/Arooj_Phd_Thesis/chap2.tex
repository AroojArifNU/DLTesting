\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries\centering}{\chaptertitlename\ \thechapter}{20pt}{\Huge}

% Using similar styling for unnumbered chapters but without "Chapter" prefix
\titleformat{name=\chapter,numberless}
  {\normalfont\huge\bfseries\centering}{}{0pt}{\Huge}

\titlespacing*{\chapter}{0pt}{50pt}{40pt} % Adjust vertical spacing before and after the title


\chapter{Literature Review} % Ensures chapter numbering starts correctly
\label{chp:2}
\section{Overview} % This will now be Section 1.1, not 0.1

\subsection{Coverage Criteria for Deep Learning Models}

\begin{table}[h]
    \centering
    \begin{tabular}{|p{4cm}|p{5cm}|p{5cm}|}
    \hline
    \textbf{Existing Coverage Methods} & \textbf{Description} & \textbf{Limitation} \\
    \hline
    Neuron Coverage & Measures the model's logic use by counting activated neurons from test inputs. & Doesn't capture all potential DNN behaviors and can achieve high coverage with few inputs; it is a coarse measure. \\
    \hline
    k-Multisection Neuron Coverage & Divides neuron activation values observed during training into k buckets and counts how many buckets are covered by a set of inputs. & Loses information on activations beyond the observed range during aggregation. \\
    \hline
    DeepCover & Considers condition-decision dependencies between adjacent DNN layers. & Limited to small, feedforward, fully-connected networks; doesn't generalize to complex architectures like RNNs or LSTMs. \\
    \hline
    DeepCT & Inspired by combinatorial testing, assesses logic use by the fraction of neurons activated in each layer. & Lacks consideration for inter-layer relationships and hasn't been proven to scale to real-world DNNs. \\
    \hline
    \end{tabular}
    \caption{Coverage Methods, Descriptions, and Limitations}
    \label{table:coverage_methods}
    \end{table}

\subsection{Test Case Generation for Deep Learning Models}

    


\begin{table}[h]
    \centering
    \begin{tabular}{|p{3.5cm}|p{5.5cm}|p{5.5cm}|}
    \hline
    \textbf{Existing Methods} & \textbf{Description} & \textbf{Limitation} \\
    \hline
    Joint Optimization & Modifies an existing input through image manipulations recursively until it triggers different behavior in the model. & Time-consuming and produces a low ratio of impactful test inputs compared to the total tested/generated. \\
    \hline
    Greedy Search & Applies random transformations to an existing test input until a suitable test input is identified. & Similar to joint optimization, it is also time-intensive and results in a low number of effective test inputs relative to the total tested. \\
    \hline
    \end{tabular}
    \caption{Summary of Existing Test Input Generation Methods}
    \label{table:test_input_generation_methods}
    \end{table}
    
	
\begin{table}[h]
    \centering
    \begin{tabular}{|p{6cm}|p{6cm}|}
    \hline
    \textbf{Existing Approaches} & \textbf{Limitations} \\
    \hline
    Collecting as much real-world data as possible and manually labeling it for correctness. & The process requires a lot of manual effort. \\
    \hline
    Comparing outputs across multiple DNNs for the same task, identifying discrepancies as corner cases. & Can misclassify inputs if all models agree, due to shared biases or errors. Limited to tasks with multiple reliable models, which may not always be available. \\
    \hline
    \end{tabular}
    \caption{Limitations of Existing Approaches in DNN Testing}
    \label{table:existing_approaches_limitations}
    \end{table}

\begin{landscape}
    \begin{xltabular}{\linewidth}{|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}p{3.5cm}|>{\raggedright\arraybackslash}p{6cm}|>{\raggedright\arraybackslash}p{2.5cm}|>{\raggedright\arraybackslash}p{3cm}|} % Adjust '3cm' as needed
    \caption{Summary of Test Methodologies and Their Characteristics} \\
    \hline
    \rowcolor[HTML]{EFEFEF} 
    \textbf{Methodology} & \textbf{Dataset} & \textbf{Benchmark} & \textbf{Limitation/Future Work} & \textbf{Coverage Criteria} & \textbf{Test Generation} \\ \endhead
    
    Symbolic execution with local explainability. LIME provides explanations for predictions\cite{Agarwal} & German Credit Data, Adult census income, Bank marketing, US Executions, Fraud Detection, Raw Car Rentals, Credit data, Census data & THEMIS (Algorithm) The technique produces 3.72 times more successful test cases than existing state-of-the-art. & FW: Expand to text and image domains FW: Measure symbolic execution efficacy using neuron coverage, boundary value coverage. & -- & Concolic \\ \hline
    
    
    Concolic testing method \cite{Youcheng} & \makecell[lt]{ MNIST\\  CIFAR-10} & DeepXplore, DeepTest, DeepCover, and DeepGauge & & \makecell[lt]{NC, SSC, NBC} & Concolic \\ \hline
    \cellcolor[HTML]{FFFFFF}Whitebox framework for testing DL systems, introducing neuron coverage for test measurement \cite{Kexin}& \makecell[lt]{ MNIST\\ ImageNet\\ Driving\\ VirusTotal\\ Drebin} & \makecell[lt]{LeNet variations\\ State-of-the-art\\ image classifiers \\ Nvidia DAVE \\ PDF malware detectors\\ Android app\\ malware detectors} & Inherits differential testing constraints. & NC & Dual-optimisation \\ \hline
    Automates testing for DNN-driven autonomous cars \cite{Yuchi}& Udacity self driving car challenge 2 & \makecell[lt]{Chauffeur-\\ Epoch\\ Rambo-S1\\ Rambo-S2\\ Rambo-S3} & \makecell[lt]{L:missing some realistic cases.\\ L: restricted only steering angle,\\ not focus on brake and accelerator\\ L: cannot simulate complex road scene}. & NC & Greedy search \\ \hline
    White box methodology, Proposed four novel test criteria tailored to DNN, structural features. able to capture and quantify causal relations existing in a DNN, Achieved balance between bug finding ability and computational cost \cite{Sun}  & MNIST, CIFAR-10, ImageNet & State-of-the-art neural networks of different sizes (from a few hundred up to millions of neurons) to demonstrate their utility with respect to four aspects: bug finding, DNN safety statistics, testing efficiency, DNN internal structure analysis & & MC/DC & Symbolic execution \\ \hline
    Proposed criteria facilitate the understanding of DNNs as well as the test data quality from different levels and angles\cite{Ma} & \makecell[lt]{MNIST, ImageNet} & \makecell[lt]{LeNet-1\\ LeNet-4\\ LeNet-5,\\ VGG-19,\\ ResNet-50} & \makecell[lt]{More diverse datasets \\and DL architectures needed.\\ Check on real-world systems.} & NBC & Gradient descent methods \\ \hline
    An unsupervised learning framework to synthesize realistic driving scenes to test inconsistent behaviors\cite{Zhang} & Udacity Training Udacity Test Ep1 Udacity Test Ep2 Youtube Ep1 Youtube Ep2 & Autumn, Chauffeur & \makecell[lt]{Lack a good standard to evaluate image\\ quality (i.e., realism). Udacity dataset is \\relatively small and the \\autonomous driving models are \\quite simple. Only focus on steering\\ wheel.} & -- & Mutation testing \\ \hline
    An automated fuzz testing framework for hunting potential defects of general-purpose DNNs\cite{Xie} & MNIST, CIFAR-10, ImageNet & \makecell[lt]{LeNet-1\\ LeNet-4\\ LeNet-5\\ RN-20\\ VGG-16\\ MobileNet\\ RN-50} & NC cannot generate effective results to evaluate the models with various quality. NC is less effective in error triggering test detection and sensitive defect detection. & \makecell[lt]{NC\\ KMNC\\ NBC\\ SNAC\\ KNC\\ KNC} & Metamorphic mutation \\ \hline
    
    \end{xltabular}
    
    \end{landscape}